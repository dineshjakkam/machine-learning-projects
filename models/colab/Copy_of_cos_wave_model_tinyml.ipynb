{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of cos_wave_model_tinyml.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOSnbsIAeTW0WwJHCW+oFmo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dineshjakkam/machine-learning-projects/blob/master/models/colab/Copy_of_cos_wave_model_tinyml.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cY5V4UWHGhKH",
        "colab_type": "text"
      },
      "source": [
        "# Understanding the basics of TinyML\n",
        "* The goal of this project is to train a simple model that can take a value x, \n",
        "and predicts its cos *(trignometric function)*, y.\n",
        "\n",
        "* In a real-world if you need a cos value, we can just directly call it as cos(x). But as part of this learning experience, we train a model using TensorFlow lite framework to predict its cosine given a value x.\n",
        "* Later will deploy this model onto the ARM based microcontroller and control one of its peripherals through the deployed model inference."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ej0rszDRFhGF",
        "colab_type": "text"
      },
      "source": [
        "## Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCyj7FhPB6EA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Install TensoFlow Library\n",
        "!pip install tensorflow==2.0\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import math"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_LwglMPaGbrM",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QLs0Y3xeFUEO",
        "colab_type": "text"
      },
      "source": [
        "## Generating samples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PiNtPrqZCoOa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SAMPLES = 1000\n",
        "# Seed value to get the same random numbers each time we run this\n",
        "# notebook. This can be of any value\n",
        "SEED = 1993\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "\n",
        "# np.random.unifrom generates the uniformly distributed random value \n",
        "# starting 0 to 2*pi, which cover complete sine wave oscillation\n",
        "x_values = np.random.uniform(low=0, high=2*math.pi, size=SAMPLES)\n",
        "\n",
        "# Shuffle the values to make sure they are not in order\n",
        "np.random.shuffle(x_values)\n",
        "\n",
        "# calculate corresponding cos values\n",
        "y_values = np.cos(x_values)\n",
        "\n",
        "# Plot the values using matplotlib\n",
        "# b dot indicates blue dots\n",
        "plt.plot(x_values, y_values, 'b.')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzFLUvVtFo1C",
        "colab_type": "text"
      },
      "source": [
        "### Add noise to the samples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_1wCOt2ETsK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Add a small random number to each y_value\n",
        "y_values += 0.1 * np.random.randn(*y_values.shape)\n",
        "\n",
        "# Plot the values using matplotlib\n",
        "# b dot indicates blue dots\n",
        "plt.plot(x_values, y_values, 'b.')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06l1LOsvFvEy",
        "colab_type": "text"
      },
      "source": [
        "### Split the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHMRIgSJFP4l",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "# We use 60% of data for training, 20% for validation and the\n",
        "# remianing 20% for testing. Split the indices as required\n",
        "TRAIN_SPLIT = int(0.6*SAMPLES)\n",
        "TEST_SPLIT = int(0.2*SAMPLES + TRAIN_SPLIT)\n",
        "\n",
        "# Given two indices np.split chop the data into three parts\n",
        "x_train, x_validate, x_test = np.split(x_values, [TRAIN_SPLIT, TEST_SPLIT])\n",
        "y_train, y_validate, y_test = np.split(y_values, [TRAIN_SPLIT, TEST_SPLIT])\n",
        "\n",
        "assert (x_train.size + x_validate.size + x_test.size) == SAMPLES\n",
        "\n",
        "# Plot the data is each partition in different colors\n",
        "plt.plot(x_train, y_train, 'b.', label=\"Train\")\n",
        "plt.plot(x_validate, y_validate, 'y.', label=\"Validate\")\n",
        "plt.plot(x_test, y_test, 'r.', label=\"Test\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYL_z9hyB7Lf",
        "colab_type": "text"
      },
      "source": [
        "## To create our model, we are going to design a simple neural newtork\n",
        "\n",
        "\n",
        "1.   Create a sequential model using Keras\n",
        "2.   Define three dense layers with 16 neurons in the intermediate layers\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_d3WPPhFCois",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "model = tf.keras.Sequential()\n",
        "\n",
        "# First layers takes a scalar input and feeds it through 16 neurons\n",
        "# The *rectified linear unit* (ReLu) activation function, decide wether\n",
        "# to activate the neuron or not\n",
        "model.add(layers.Dense(16, activation='relu', input_shape=(1,)))\n",
        "\n",
        "# second desned layer\n",
        "model.add(layers.Dense(16, activation='relu'))\n",
        "\n",
        "# Final layer is a single, since we want to output a single value\n",
        "model.add(layers.Dense(1))\n",
        "\n",
        "# Compile the model using standard optimizer and loss function for regression\n",
        "model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_t-OcvBHEi_",
        "colab_type": "text"
      },
      "source": [
        "### Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qXd4QzcbHIBs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model.fit(x_train, y_train, epochs=600, batch_size=16,\n",
        "                    validation_data=(x_validate, y_validate))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8vJfBSdWHtbX",
        "colab_type": "text"
      },
      "source": [
        "## Graphs for the obtained results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YtihYSPzKC19",
        "colab_type": "text"
      },
      "source": [
        "### Plot the loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BUKeW5ldHx31",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# training loss\n",
        "loss = history.history['loss']\n",
        "# validation loss\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(loss)+1)\n",
        "\n",
        "plt.plot(epochs, loss, 'g.', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'b.', label='Validation Loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUbYLVcxH84r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# To better see the result skip the first 100 epochs \n",
        "SKIP = 100\n",
        "plt.plot(epochs[SKIP:], loss[SKIP:], 'g.', label='Training Loss')\n",
        "plt.plot(epochs[SKIP:], val_loss[SKIP:], 'b.', label='Validation Loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKvKCTQcJQmw",
        "colab_type": "text"
      },
      "source": [
        "### Plot the mean absolute error"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6cbhcoHJTFG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mae = history.history['mae']\n",
        "val_mae = history.history['val_mae']\n",
        "\n",
        "plt.plot(epochs[SKIP:], mae[SKIP:], 'g.', label='Training MAE')\n",
        "plt.plot(epochs[SKIP:], val_mae[SKIP:], 'b.', label='Validation MAE')\n",
        "plt.title('Training and validation mean absolute error')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('MAE')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5i9BnaNsRuJM",
        "colab_type": "text"
      },
      "source": [
        "## Testing\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-hPVoqGRvxo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Calculate and print the loss on the test dataset\n",
        "loss = model.evaluate(x_test, y_test)\n",
        "\n",
        "#Make predictions based on our test dataset\n",
        "predictions = model.predict(x_test)\n",
        "\n",
        "# Graph the predictions against the actual values\n",
        "plt.clf()\n",
        "plt.title('Comparison of prediction and actual values')\n",
        "plt.plot(x_test, y_test, 'b.', label='Actual')\n",
        "plt.plot(x_test, predictions, 'r.', label='Predictions')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gp9mUOqHWPBf",
        "colab_type": "text"
      },
      "source": [
        "## Convert the model to the TensorFlow Lite format"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jspHHdHxWVI9",
        "colab_type": "text"
      },
      "source": [
        "### Without quantization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RNncAPMXWYYY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# save the model to disk\n",
        "open(\"cos_model.tflite\", \"wb\").write(tflite_model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTUr5ITLYngD",
        "colab_type": "text"
      },
      "source": [
        "### With quatization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvrbD3KbYqMh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "# indicate that we want to perform default optimization which\n",
        "# includes quantization\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "\n",
        "# To create a quantized model that runs as efficiently as possible,\n",
        "# we neeed to provide a *representative dataset* -  a set of numbers\n",
        "# that represent the full range of input values of the dataset on which \n",
        "# the model was trained (as generator function)\n",
        "def representative_dataset_generator():\n",
        "  for value in x_test:\n",
        "    # Each scalar value must be inside of a 2D array that is wrapped in a list\n",
        "    yield [np.array(value, dtype=np.float32, ndmin=2)]\n",
        "\n",
        "converter.representative_dataset = representative_dataset_generator\n",
        "\n",
        "#convert the model\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# save the model to disk\n",
        "open(\"cos_model_quantized.tflite\", \"wb\").write(tflite_model)\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}